{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data. Label is the numeric label (0-9). Other columns in X data represent the pixel intensity (0-255) of the image\n",
    "# at the designated pixel. The MNIST data is already quite clean and well pre-processed, so we can just feed the data into\n",
    "# our model.\n",
    "\n",
    "X_train = pd.read_csv(\"mnist_train.csv\")\n",
    "y_train = X_train.label\n",
    "X_train.drop('label', axis = 1, inplace = True)\n",
    "\n",
    "X_test = pd.read_csv(\"mnist_test.csv\")\n",
    "y_test = pd.DataFrame(X_test.label)\n",
    "X_test.drop('label', axis = 1, inplace = True)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "# Function that shifts the original images by dy in the y direction and dx in the x direction (using image coordinates)\n",
    "# i.e. the origin is in the top left corner of the image.\n",
    "def shift_digit(image, dx, dy):\n",
    "    image = image.reshape(28,28)\n",
    "    shift_image = np.array(shift(image, [dy, dx], cval = 0, mode = \"constant\"))\n",
    "    return shift_image.reshape([-1])\n",
    "\n",
    "\n",
    "# Convert to a list, to make it less of a hassle to append to the data set\n",
    "X_train_expanded = X_train.tolist()\n",
    "y_train_expanded = y_train.tolist()\n",
    "\n",
    "# Augment the data, by shifting each image four pixels to the right, four pixels to the left, four pixels down,\n",
    "# then four pixels up. This will lead to better generalization and accuracy.\n",
    "for dx, dy in ((4,0), (-4, 0), (0, 4), (0, -4)):\n",
    "    for ix in range (0, len(X_train)):\n",
    "        shifted_image = shift_digit(X_train[ix], dx, dy)\n",
    "        X_train_expanded.append(shifted_image.tolist())\n",
    "        y_train_expanded.append(y_train[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing shift_digit function\n",
    "# original = X_train_expanded[1]\n",
    "# shifted = X_train_expanded[60001]\n",
    "\n",
    "# plt.imshow(original.reshape(28,28), cmap = \"Greys\")\n",
    "# plt.show()\n",
    "# plt.imshow(shifted.reshape(28,28), cmap = \"Greys\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=8, weights='distance')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "image_clf = KNeighborsClassifier(n_neighbors = 5, weights = 'distance', n_jobs = 8)\n",
    "image_clf.fit(X_train_expanded, y_train_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_test_pred = image_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5881    4    5    2    0    5   19    2    1    4]\n",
      " [   2 6699   12    3    3    0    2   14    2    5]\n",
      " [  55   74 5646   27    6    8   11  100   21   10]\n",
      " [  10   16   36 5884    0   60    4   40   51   30]\n",
      " [   5   57    1    1 5591    0   18   13    1  155]\n",
      " [  18   19    4   81    9 5170   71    5   13   31]\n",
      " [  17   13    1    0    5   23 5857    0    2    0]\n",
      " [   3   70   13    2   21    2    0 6079    2   73]\n",
      " [  25   92   15   80   30   99   20   18 5399   73]\n",
      " [  18   11    6   43   50   13    4   85   13 5706]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(image_clf, X_train, y_train, cv = 2, n_jobs = 8)\n",
    "conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "print (conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors Classifier Model Evaluation:\n",
    "\n",
    "Model_v1 had approximatley a 97% cross validation accuracy on the training set, which is an excellent accuracy score, we can assume that since we are using an expanded data set, our accuracy will be very similar (I don't really want to run a cross validation on the exact same data set but expanded; it will yield almost the exact same/similar results but take way longer). Like version 1, the model has 96.91% accuracy on the test set (makes sense since we are just using an expanded data set, so the original , proving that it generalizes quite and can provide accurate predictions on unseen data.\n",
    "\n",
    "Using 5 neighbors and distance weighting in the model in addition to the augmented data set, the model achieves an accuracy score of about 97%, which is quite good, proving that it is quite generalizable, not overfit, and can perform well on unseen data.\n",
    "\n",
    "The Confusion Matrix for this data set (columns from 0-9, representing the classified digit):\n",
    "\n",
    "\n",
    "    [[5881    4    5    2    0    5   19    2    1    4]\n",
    "     [   2 6699   12    3    3    0    2   14    2    5]\n",
    "     [  55   74 5646   27    6    8   11  100   21   10]\n",
    "     [  10   16   36 5884    0   60    4   40   51   30]\n",
    "     [   5   57    1    1 5591    0   18   13    1  155]\n",
    "     [  18   19    4   81    9 5170   71    5   13   31]\n",
    "     [  17   13    1    0    5   23 5857    0    2    0]\n",
    "     [   3   70   13    2   21    2    0 6079    2   73]\n",
    "     [  25   92   15   80   30   99   20   18 5399   73]\n",
    "     [  18   11    6   43   50   13    4   85   13 5706]]\n",
    "\n",
    "As evidenced by the confusion matrix, model performance on 8's, 6's, and 9's are the worst. 6's often get classified as 5's, 8's often get classified as 3's, and 9's often get classified as 4's. These all make sense since these numbers are very structurally similar, so this type of error will always exist to some degree (and sometimes even humans can't tell the difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KNN_MNIST_ImageClassifier_v2']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to file called \"KNN_MNIST_ImageClassifier_v2\"\n",
    "joblib.dump(image_clf, \"KNN_MNIST_ImageClassifier_v2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
