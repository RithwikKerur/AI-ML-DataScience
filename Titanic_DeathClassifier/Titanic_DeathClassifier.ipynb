{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "# Show all columns when displaying .head() or .describe()\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into features and labels\n",
    "X_train = pd.read_csv(\"train.csv\")\n",
    "y_train = X_train[\"Survived\"]\n",
    "X_train.drop([\"Survived\"], axis = 1, inplace = True)\n",
    "\n",
    "X_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Pclass       891 non-null    int64  \n",
      " 2   Name         891 non-null    object \n",
      " 3   Sex          891 non-null    object \n",
      " 4   Age          714 non-null    float64\n",
      " 5   SibSp        891 non-null    int64  \n",
      " 6   Parch        891 non-null    int64  \n",
      " 7   Ticket       891 non-null    object \n",
      " 8   Fare         891 non-null    float64\n",
      " 9   Cabin        204 non-null    object \n",
      " 10  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Cabin\" feature contains a lot of missing values; it will be better to simply drop that feature rather than impute it. The \"Name\" and \"Ticket\" features most likely are not going to affect our predicted too adversely (although there could certainly be a relationship between them and survival rate) and processing names and ticket numbers for useful information will prove quite difficult; so ignore them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Build Pipeline to impute numeric data\n",
    "num_pipeline = Pipeline(steps=[(\"Imputer\", SimpleImputer(strategy = 'mean'))])\n",
    "\n",
    "# Build Pipeline to impute categorial data\n",
    "cat_pipeline = Pipeline(steps=[(\"Imputer\", SimpleImputer (strategy = 'most_frequent')),\n",
    "                               (\"LabelEncoder\", OneHotEncoder())\n",
    "    \n",
    "])\n",
    "\n",
    "# Use a ColumnTransformer to join the categorical and numeric imputed and encoded data\n",
    "preprocess = ColumnTransformer(transformers = [(\"Numeric\", num_pipeline, [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]),\n",
    "                                               (\"Categorical\", cat_pipeline, [\"Sex\", \"Embarked\"])\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier (n_estimators = 250, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After experimenting with several models(KNN, SVM, RandomForestClassifiers), a random forest classifier seems to perform the best on this data set (with about 81% cross validation accuracy score). So, train a classifier with 250 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Preprocessor',\n",
       "                 ColumnTransformer(transformers=[('Numeric',\n",
       "                                                  Pipeline(steps=[('Imputer',\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  ['Pclass', 'Age', 'SibSp',\n",
       "                                                   'Parch', 'Fare']),\n",
       "                                                 ('Categorical',\n",
       "                                                  Pipeline(steps=[('Imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('LabelEncoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['Sex', 'Embarked'])])),\n",
       "                ('Model',\n",
       "                 RandomForestClassifier(n_estimators=250, random_state=0))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = Pipeline(steps=[\n",
    "    ('Preprocessor', preprocess),\n",
    "    ('Model', model)\n",
    "])\n",
    "\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8103571652752495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use cross validation to score the model on the training set (since our dataset is rather small and we can't afford to split it)\n",
    "# into a training and validation sets\n",
    "\n",
    "accuracy = cross_val_score(final_model, X_train, y_train, cv = 5)\n",
    "print (accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0\n",
      " 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test data and save predictions to a csv for Kaggle submission\n",
    "\n",
    "predictions = final_model.predict(X_test)\n",
    "print (predictions)\n",
    "#  submission = pd.DataFrame({\"PassengerId\": X_test.PassengerId,\n",
    "#                          \"Survived\": predictions})\n",
    "# submission.to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
